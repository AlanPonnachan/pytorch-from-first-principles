{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8db8ed8",
   "metadata": {},
   "source": [
    "### Problem 1 - The Multi-Head Attention Score\n",
    "\n",
    "\n",
    "In the Transformer paper (\"Attention is All You Need\"), the core math is:\n",
    "$$\\text{Score} = QK^T$$\n",
    "Where $Q$ and $K$ are 4D tensors: `(Batch, Heads, Sequence_Length, Features)`. \n",
    "\n",
    "###  Setup\n",
    "\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Create Toy Data (Research Scale)\n",
    "# B=2 (Batch size), H=4 (Heads), L=10 (Seq Length), D=32 (Feature Dim)\n",
    "B, H, L, D = 2, 4, 10, 32\n",
    "Q = torch.randn(B, H, L, D)\n",
    "K = torch.randn(B, H, L, D)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Challenge: Implementation\n",
    "\n",
    "You need to calculate the attention score matrix of shape `(B, H, L, L)`. \n",
    "\n",
    "1.  **Method A (The \"Messy\" Way):** Use `torch.matmul`. \n",
    "2.  **Method B (The \"Better\" Way):** Use `torch.einsum`.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04396d39",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Hint</summary>\n",
    "\n",
    "1.  **Method A**\n",
    "    *   *Hint:* You cannot multiply `(B, H, L, D)` by `(B, H, L, D)`. You must transpose the second tensor to `(B, H, D, L)` first.\n",
    "2.  **Method B** \n",
    "    *   *Hint:* The formula is `'bhld, bhmd -> bhlm'`. \n",
    "    *   **Logic:** `b` and `h` stay the same. `l` is the row of Q, `m` is the row of K. `d` is the dimension that gets \"multiplied and summed\" (the dot product).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "669b551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores using matmul: torch.Size([2, 4, 10, 10])\n",
      "Attention scores using einsum: torch.Size([2, 4, 10, 10])\n",
      "Do the methods match? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/attention_experiment')\n",
    "\n",
    "B, H, L, D = 2, 4, 10, 32\n",
    "Q = torch.randn(B, H, L, D)\n",
    "K = torch.randn(B, H, L, D)\n",
    "\n",
    "#using matmul\n",
    "attention_scores_matmul = torch.matmul(\n",
    "        Q, K.transpose(-2, -1)\n",
    ")\n",
    "\n",
    "print(f'Attention scores using matmul: {attention_scores_matmul.size()}')\n",
    "\n",
    "#using einsum\n",
    "attention_scores_einsum = torch.einsum(\n",
    "    \"bhld,bhmd->bhlm\", Q, K\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Attention scores using einsum: {attention_scores_einsum.size()}')\n",
    "\n",
    "# Verification\n",
    "matches = torch.allclose(attention_scores_matmul, attention_scores_einsum, atol=1e-6)\n",
    "print(f\"Do the methods match? {matches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c4620",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Post-Mortem (Problem 1)</summary>\n",
    "\n",
    "\n",
    "\n",
    "####  Matmul vs. Einsum\n",
    "*   **The Matmul Way:** `torch.matmul(Q, K.transpose(-2, -1))`\n",
    "    *   **Pros:** Familiar to those coming from linear algebra.\n",
    "    *   **Cons:** You have to remember *which* dimensions to transpose. If you have a 5D tensor (e.g., `[B, H, T, L, D]`), `transpose(-2, -1)` might not be what you want. It is **positional**.\n",
    "*   **The Einsum Way:** `torch.einsum(\"bhld,bhmd->bhlm\", Q, K)`\n",
    "    *   **Pros:** It is **declarative**. You are stating: \"Take dimension $d$ from the first and dimension $d$ from the second, multiply them, and sum them up.\" You don't care where $d$ is located; you just name it.\n",
    "    *   **Cons:** Small learning curve for the notation string.\n",
    "\n",
    "\n",
    "####  Connection to Strides\n",
    "When you called `K.transpose(-2, -1)`, did PyTorch move data? **No.** (Refer back to Notebook 01). It just swapped the strides. \n",
    "When `torch.matmul` runs, it sees that `K` is non-contiguous and handles the internal memory jumps. \n",
    " `einsum` often optimizes the operation internally (using the `opt_einsum` logic), sometimes making it faster than multiple `transpose` and `matmul` calls for complex operations.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b3f92",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b05d61",
   "metadata": {},
   "source": [
    "### Problem 2: The Pairwise Distance Kernel (Broadcasting)\n",
    "\n",
    " letâ€™s tackle the **Expansion Trick**. This is used in papers involving **Contrastive Learning** (like CLIP or SimCLR), where you compare every image feature in a batch to every text feature.\n",
    "\n",
    "**The Setup:**\n",
    "```python\n",
    "# A: 5 points in 2D space (e.g., Target centroids)\n",
    "A = torch.tensor([\n",
    "    [0.0, 0.0],\n",
    "    [1.0, 1.0],\n",
    "    [2.0, 2.0],\n",
    "    [3.0, 3.0],\n",
    "    [4.0, 4.0]\n",
    "])\n",
    "\n",
    "# B: 3 points in 2D space (e.g., New data points)\n",
    "B = torch.tensor([\n",
    "    [0.5, 0.5],\n",
    "    [2.5, 2.5],\n",
    "    [10.0, 10.0]\n",
    "])\n",
    "```\n",
    "\n",
    "**Your Challenge:**\n",
    "Compute a `(5, 3)` matrix where `output[i, j]` is the Squared Euclidean Distance between `A[i]` and `B[j]`.\n",
    "\n",
    "1.  **Requirement:** Do NOT use `for` loops.\n",
    "2.  **Requirement:** Use broadcasting with the `None` (unsqueeze) trick.\n",
    "3.  **The Formula:** $(x_1 - x_2)^2 + (y_1 - y_2)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017b2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape: torch.Size([5, 2]), B.shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# A: 5 points in 2D space (e.g., Target centroids)\n",
    "A = torch.tensor([\n",
    "    [0.0, 0.0],\n",
    "    [1.0, 1.0],\n",
    "    [2.0, 2.0],\n",
    "    [3.0, 3.0],\n",
    "    [4.0, 4.0]\n",
    "])\n",
    "\n",
    "# B: 3 points in 2D space (e.g., New data points)\n",
    "B = torch.tensor([\n",
    "    [0.5, 0.5],\n",
    "    [2.5, 2.5],\n",
    "    [10.0, 10.0]\n",
    "])\n",
    "\n",
    "print(f\"A.shape: {A.shape}, B.shape: {B.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971e5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix Shape: torch.Size([5, 3])\n",
      "tensor([[  0.5000,  12.5000, 200.0000],\n",
      "        [  0.5000,   4.5000, 162.0000],\n",
      "        [  4.5000,   0.5000, 128.0000],\n",
      "        [ 12.5000,   0.5000,  98.0000],\n",
      "        [ 24.5000,   4.5000,  72.0000]])\n"
     ]
    }
   ],
   "source": [
    "#  Expand dimensions using 'None'\n",
    "# A[:, None, :] -> (5, 1, 2)\n",
    "# B[None, :, :] -> (1, 3, 2)\n",
    "diff = A[:, None, :] - B[None, :, :]\n",
    "\n",
    "#  Square the differences\n",
    "# Shape stays (5, 3, 2)\n",
    "sq_diff = diff ** 2\n",
    "\n",
    "# Sum over the feature dimension (the last dimension, dim=2)\n",
    "# (5, 3, 2) -> (5, 3)\n",
    "dist_matrix = sq_diff.sum(dim=2)\n",
    "\n",
    "print(f\"Distance Matrix Shape: {dist_matrix.shape}\")\n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745ec60",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Post-Mortem (Problem 2)</summary>\n",
    "\n",
    "**Q1: What is the shape of the intermediate tensor `diff`?**\n",
    "*   **Answer:** $(5, 3, 2)$.\n",
    "*   **Deep Dive:** In  memory (RAM), PyTorch just created $5 \\times 3 \\times 2 = 30$ floating-point numbers. \n",
    "\n",
    "**Q2: The Memory Warning**\n",
    "Imagine you are implementing a research paper with a batch size of 1000 images, and each image has 512 features.\n",
    "*   $A$ is $(1000, 512)$\n",
    "*   $B$ is $(1000, 512)$\n",
    "*   `A[:, None, :] - B[None, :, :]` creates a tensor of $(1000, 1000, 512)$.\n",
    "*   That is **512 million numbers**. At 4 bytes per float, that is **2 GB of GPU RAM** just for one subtraction!\n",
    "*   **Lesson:** Broadcasting is beautiful, but if your dimensions are large, you will hit an `Out of Memory (OOM)` error. This is why researchers often use the formula $(a-b)^2 = a^2 + b^2 - 2ab$ with `torch.matmul`, because it avoids that huge 3D intermediate tensor.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f59080",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1c672",
   "metadata": {},
   "source": [
    "### Problem 3: Manual Convolution (Unfold / Sliding Windows)\n",
    "\n",
    " In many research papers (like **Swin Transformers** or **Graph Neural Networks**), you don't use standard Convolutions. You need to extract \"patches\" or \"neighborhoods.\"\n",
    "\n",
    " A convolution is just a dot product over a sliding window. To do this efficiently, we \"unroll\" the windows into a matrix.\n",
    "\n",
    "**The Setup:**\n",
    "We have a 1D signal (representing time or a flattened image).\n",
    "```python\n",
    "# A signal of 10 values\n",
    "signal = torch.tensor([10., 20., 30., 40., 50., 60., 70., 80., 90., 100.])\n",
    "```\n",
    "\n",
    "**Your Challenge:**\n",
    "Use the `.unfold()` method to create a sliding window view.\n",
    "1.  **Window Size:** 3\n",
    "2.  **Stride:** 1 (The window moves 1 step at a time)\n",
    "3.  **Goal:** Transform `signal` into a 2D tensor where each row is a window:\n",
    "    ```text\n",
    "    [[10, 20, 30],\n",
    "     [20, 30, 40],\n",
    "     [30, 40, 50],\n",
    "     ...]\n",
    "    ```\n",
    "4.  **The \"Math\" Challenge:** Once you have the windows, define a kernel `torch.tensor([0.5, 1.0, 0.5])` and compute the convolution (dot product of each window with the kernel) using **Einsum**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d17f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Signal Shape: torch.Size([10])\n",
      "Unfolded Windows Shape: torch.Size([8, 3])\n",
      "First 3 windows:\n",
      " tensor([[10., 20., 30.],\n",
      "        [20., 30., 40.],\n",
      "        [30., 40., 50.]])\n",
      "Convolution Result Shape: torch.Size([8])\n",
      "Convolution Result:\n",
      " tensor([ 40.,  60.,  80., 100., 120., 140., 160., 180.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Our Signal\n",
    "signal = torch.tensor([10., 20., 30., 40., 50., 60., 70., 80., 90., 100.])\n",
    "\n",
    "# The Unfold operation\n",
    "# .unfold(dimension, size, step)\n",
    "# dimension=0: we are unfolding the only dimension we have\n",
    "# size=3: each window has 3 elements\n",
    "# step=1: move the window 1 element at a time\n",
    "windows = signal.unfold(0, 3, 1)\n",
    "\n",
    "print(f\"Original Signal Shape: {signal.shape}\")\n",
    "print(f\"Unfolded Windows Shape: {windows.shape}\")\n",
    "print(\"First 3 windows:\\n\", windows[:3])\n",
    "\n",
    "# The Kernel (for convolution)\n",
    "kernel = torch.tensor([0.5, 1.0, 0.5])\n",
    "\n",
    "\n",
    "# Compute the convolution using einsum. \n",
    "# 'windows' of shape (8, 3) and 'kernel' of shape (3).\n",
    "# We want to multiply each window by the kernel and sum them up.\n",
    "# 'ij, j -> i' \n",
    "# (i is the number of windows, j is the window size)\n",
    "\n",
    "conv_result = torch.einsum('ij, j -> i', windows, kernel)\n",
    "print(f\"Convolution Result Shape: {conv_result.shape}\")\n",
    "print(\"Convolution Result:\\n\", conv_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be7945",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Post-Mortem (Problem 3)</summary>\n",
    "\n",
    "\n",
    "In Problem 1, we saw that `transpose` changes strides. `unfold` is even more extreme.\n",
    "*   Original `signal` stride: `(1,)`\n",
    "*   `unfolded` windows stride: `(1, 1)`\n",
    "\n",
    " Usually, to go to the next \"row\" in a matrix, you have to skip many elements. But here, to go to the next \"window,\" you only skip **1** element. This is why the windows overlap! If you changed the `step` to **3**, the stride would become `(3, 1)`, meaning \"skip 3 to get to the next window.\" This would create **non-overlapping** patches (used in Vision Transformers).\n",
    "\n",
    "\n",
    "Deep Learning libraries don't actually slide a window in a `for` loop. They use a function called `im2col` (image to column), which is essentially a 2D version of `unfold`. It turns the image into a giant matrix of patches so that the convolution can be calculated as one single, massive **Matrix Multiplication** (which GPUs are incredibly fast at).\n",
    ".\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c58f3",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
